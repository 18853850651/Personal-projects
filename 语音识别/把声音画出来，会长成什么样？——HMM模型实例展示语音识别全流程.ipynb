{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、项目简介\n",
    "* 语音识别是人工智能领域的一个重要的应用场景，那么程序究竟是如何听懂语音的呢？\n",
    "* 本文将用真实的音频案例，用代码呈现语音识别的基本原理和流程。\n",
    "* 同时，将各种声音信号的MFCC矩阵进行可视化，“把声音的美丽画成图”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、基本原理\n",
    "计算机只能识别二进制的数字信息，是无法直接识别音频信息的。因此让机器具有听懂“人话”的功能，必须要将声音的模拟信号转化为数字信号；就是利用模型将声音的音频数据进行量化，并根据需求进行特征提取（一般提取声音信号的MFCC-梅尔频率倒谱系数矩阵），转化为特征矩阵。然后利用大量的相关特征举证对模型进行训练，使模型具备声音分类的功能。\n",
    "详细原理见：https://blog.csdn.net/bvngh3247/article/details/80778165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、案例数据\n",
    "* 本文采集7类声音数据（7种水果的英文读音wav文件）\n",
    "* 7类分别为：apple(苹果),banana(香蕉),orange(橘子),lime(青柠檬),\n",
    "  kiwi(猕猴桃)，peach(桃子),pineapple(菠萝)\n",
    "* 训练集各准备14个样本，测试集各一个样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、源代码及数据集地址\n",
    "* github:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、模型创建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、导入相关工具包\n",
    "* 核心工具包：hmmlearn,scipy.io.wavfile,python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wf\n",
    "import python_speech_features as sf\n",
    "import matplotlib.pyplot as mp\n",
    "import hmmlearn.hmm as hl\n",
    "# 过滤代码运行中无关的警告日志\n",
    "warnings.filterwarnings(\n",
    "    'ignore', category=DeprecationWarning)\n",
    "np.seterr(all='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、定义语音识别的各类函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义声音文件的标签和路径的映射字典函数\n",
    "def search_speeches(directory, speeches):\n",
    "    # 如果路径不是文件夹则报出异常\n",
    "    if not os.path.isdir(directory):\n",
    "        raise IOError(\"路径\" + directory + '不是文件夹')\n",
    "    # 获取文件夹中的子目录\n",
    "    for entry in os.listdir(directory):\n",
    "        # 获取分类文件夹的名称作为分类标签\n",
    "        label = directory[directory.rfind(\n",
    "            os.path.sep) + 1:]\n",
    "        # 拼接新的文件路径\n",
    "        path = os.path.join(directory, entry)\n",
    "        # 如果路径为文件夹则继续递归向内查询\n",
    "        if os.path.isdir(path):\n",
    "            search_speeches(path, speeches)\n",
    "        # 如果路径为'.wav'后缀的文件名\n",
    "        elif os.path.isfile(path) and \\\n",
    "                path.endswith('.wav'):\n",
    "            # 判断speeches中是否存在label标签\n",
    "            if label not in speeches:\n",
    "                speeches[label] = []\n",
    "            speeches[label].append(path)\n",
    "    return speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集的MFCC矩阵和标签列表\n",
    "def gen_matrix(speeches):\n",
    "    path_x, path_y = [], []\n",
    "    # 获取wav文件类型标签和文件集\n",
    "    for label, filenames in speeches.items():\n",
    "        mfccs = np.array([])\n",
    "        # 遍历每一个wav文件\n",
    "        for filename in filenames:\n",
    "            # 提取wav文件的采样率和信号值\n",
    "            sample_rate, sigs = wf.read(filename)\n",
    "            # 获取每个音频文件的mfcc\n",
    "            mfcc = sf.mfcc(sigs, sample_rate)\n",
    "            if len(mfccs) == 0:\n",
    "                mfccs = mfcc\n",
    "            else:\n",
    "                mfccs = np.append(mfccs, mfcc, axis=0)\n",
    "        path_x.append(mfccs)\n",
    "        path_y.append(label)\n",
    "    return path_x, path_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行模型训练,获取训练后的模型集\n",
    "def model_train(path_x, path_y):\n",
    "    models = {}\n",
    "    for mfccs, label in zip(path_x, path_y):\n",
    "        # 利用HMM算法创建模型\n",
    "        model = hl.GaussianHMM(\n",
    "            n_components=4, covariance_type='diag',\n",
    "            n_iter=1000)\n",
    "        # 获取每个训练样本训练得到的model\n",
    "        models[label] = model.fit(mfccs)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测,获取样本测试的标签集\n",
    "def model_pred(path_x, path_y, models):\n",
    "    pred_test_y = []\n",
    "    for mfccs in path_x:\n",
    "        # 初始化最优模型得分和对应的类别\n",
    "        best_score, best_label = None, None\n",
    "        # 获取模型和对应的标签\n",
    "        for label, model in models.items():\n",
    "            # 计算模型的测试得分\n",
    "            score = model.score(mfccs)\n",
    "            # 选择每个类别对应的最优模型参数\n",
    "            if (best_score is None) or \\\n",
    "                    best_score < score:\n",
    "                best_score, best_label = score, label\n",
    "        pred_test_y.append(best_label)\n",
    "    return pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义可视化函数，绘制wav文件对应的MFCC图像\n",
    "def visualize(path_x, path_y):\n",
    "    for mfcc, label in zip(path_x, path_y):\n",
    "        mp.matshow(mfcc.T, cmap='jet', fignum=label)\n",
    "        mp.title(label, fontsize=20)\n",
    "        mp.xlabel('Sample', fontsize=14)\n",
    "        mp.ylabel('Feature', fontsize=14)\n",
    "        mp.tick_params(which='both', top='False',\n",
    "                       labeltop='False', labelbottom='True',\n",
    "                       labelsize=10)\n",
    "        mp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、模型训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型阶段\n",
    "# 获取训练集的标签、文件字典\n",
    "train_path = 'speeches/training'\n",
    "train_speeches = {}\n",
    "train_speeches = search_speeches(\n",
    "    train_path, train_speeches)\n",
    "# print(train_speeches)\n",
    "# 获取格式化训练样本数据集\n",
    "train_x, train_y = gen_matrix(train_speeches)\n",
    "# 获取训练模型集合\n",
    "models = model_train(train_x, train_y)\n",
    "# print(len(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4、模型测试阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测阶段\n",
    "# 获取测试集的标签、文件字典\n",
    "test_path = 'speeches/testing'\n",
    "test_speeches = {}\n",
    "test_speeches = search_speeches(\n",
    "    test_path, test_speeches)\n",
    "# print(test_speeches)\n",
    "# 获取格式化训练样本数据集\n",
    "test_x, test_y = gen_matrix(test_speeches)\n",
    "# 获取预测结果集\n",
    "pred_test_y = model_pred(\n",
    "    test_x, test_y, models)\n",
    "print('True Value:\\n', pred_test_y)\n",
    "print('Predict Value:\\n', test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5、wav文件可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化各种类别的MFCC图像\n",
    "visualize(test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvenv",
   "language": "python",
   "name": "venvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
